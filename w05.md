---
layout: "layout"
permalink: /W05/
---

# Top 10 List of Week 05

1. [OS Demand Paging (Article)](https://www.javatpoint.com/os-demand-paging)<br>
This is a nice overall overview of this week's material from `javatpoint`. It briefly explains concepts like `Page Fault` and `Thrashing`. Page fault occurs when an instruction needs a page that isn't in the main memory. It has the same concept as a cache miss. Thrashing, if you've read my compilation in w04, you'll know that it'll hapen when the main memory is full which causes page swapping to occur and take more time than the actual instruction. 

2. [What is copy-on-write? (Article)](https://stackoverflow.com/questions/628938/what-is-copy-on-write)<br>
Again, a `stackoverflow` thread/blog which you usually get the most information for the time invested in reading. This week's first unfamiliar term for me is `copy-on-write`, so I thought this would be the perfect opportunity to familiarize myself with this term. copy-on-write or COW is a strategy used for use cases such as multiple requests for the same resouce. These resources are indistinguishable (perhaps checked using checksums?) and therefor can be directed to the same resource. This is maintained until someone does a `write` and therefor the modified document is copied so the person who modified it will get a different version than the other requesters which still has the previous version. This creates an efficient yet private somewhat file management system. Really interesting read, I recommend.

3. [Pro vs. Hard Coding Interview Problem - LRU Cache (LeetCode Day 24) (Video)](https://www.youtube.com/watch?v=FN8U19xxGog)<br>
I've previously mentioned LRU cache in w03, as one of the topics is about caching. This time it's a video tutorial about LRU cache by `Errichto`, one of the best in `Competitive Programing`. This video is a must watch as it displays how a seasoned programmer tackles an unknown problem by `understanding the problem`, `think about the right data structure`, struggle, and then solving the problem. Basically an LRU cache is an implmentation of a Hash Map / Hash Table which usually uses Linked Lists for collision resolution. You should learn about the basic `commands` of an LRU cache which is to `get` from the cache and also `put`. The action of get and put is what determines an item being the `Least` recent, and therefore being erased from the cache.This is such a great interview question and I highly recommend.

4. [When and Why to use a Least Frequently Used (LFU) cache with an implementation in Golang (Blog)](https://ieftimov.com/post/when-why-least-frequently-used-cache-implementation-golang/)<br>
This blog is a hidden gem which describes deeply about Least Frequently Used or LFU cache by Ilija. Ilija divides this article into bite-sized sections such as `why use LFU cache`, `data structure used`, and `structs/types needed`. You can think of LFU as a `Content Delivery Network` or CDN, which is widely used by services where users requests files frequently. Memory is limited, therefore, to avoid cache misses, CDNs use LFU cache algorithm to keep the frequently used files and remove the less frequent ones. The data structured used, same as an LRU cache is hash maps and possibly linked lists if you implement your own hash table. This is such rich article, and the effort shows as he/she inclused diagrams and code snippets with the explanation. As a bonus, you'll be able to understand `golang` from this article, such a nice read.

5. [Operating System - Virtual Memory (Article)](https://www.tutorialspoint.com/operating_system/os_virtual_memory.htm)<br>
To sum up the previous materials, this article is a nice overview of topics such as `Demand Paging`, `reference string`, and the various page replacing algorithms such as `FIFO`, `Optimal Page`, `LRU`, `Page Buffering`, `LFU`, and `MFU`. Most of these I have explained in the top of this week's list. One thing that I'd like to familiarize myself with is `Optimal Page Algorithm`, which claims to have the lowest page-fault out of all algorithms. This algorithm exists and is called OPT or MIN, which I might take a deeper dive in the next numbers on the list. The basic premise of optimal page algorithm is to replace the page that has the biggest amount of time in which it has not been accessed in, so I guess it should be called `Last Used` cache algorithm?

6. [Mock System Design Interview - Build a system like TikTok (SDE 1 level) (Video)](https://www.youtube.com/watch?v=vpa2vQdF-AI&t=1797s)<br>
Now this is a fun video for you folks in search of a SDE internship. It uses lots of concepts from previous week, such as Distributed File Systems and Caching which is used by a Content Delivery Network. It also touches future topics such as concurrency with message queues. If you're an aspiring software developer, then one of the skils to have is to design a system.

7. [What does the $ mean when running commands? (Article)](https://stackoverflow.com/questions/19986306/what-does-the-mean-when-running-commands)<br>
So one of my biggest unknowns is the `$` or dollar sign, usually present in tutorials where code snippets are included. Usually these code/commands are preceded with a dollar sign. So after reading this, actually it is nothing special! It just means that is is the beginning of a command in a linus/unix based system.

8. [ZooKeeper in 15 Minutes (Article)](https://dzone.com/articles/zookeeper-in-15-minutes)<br>
Time for a curveball, this article explains ZooKeeper better than anything I've ever read. Zookeeper is used to coordinate distributed systems and is used by hadoop and kafka. It is also called a distributed key-value store, like a hash table. Many advantages of zookeper are consistency, atomicity and reliability. Services it offers are naming service, cluster management, leader election, and locking. These all could be explained individually in a post and I'll touch up on them in future week compilations.

9. [Will More RAM Make your PC Faster?? (2020) (Video)](https://www.youtube.com/watch?v=kUFWalEf31w)<br>
This is the mandatory Linus Tech Tips video. Surprisingly, it touches on concepts such as Page Files which is discussed in this week's topic about memory virtualization. To sum up, 4gb is unusable in today's standard, 8gb is nice for day-to-day usage, 16gb-32gb if you have a pretty heavy worload such as editing, compiling. Above that, you'll probably don't need it, unless you're using it for deep learning.

10. [My Interview Experience with Shopee / Garena / Sea Group (Blog)](https://forthright48.com/interview-with-shopee-garena/)<br>
You might be confused why I put this inside my links compilation, but if you read the article you'll know why. Surprisingly, this article is what first made me learn about Operating Systems. It is such a nice intro and motivation on why you should learn and practice these operating systems concepts so that you can have a better chance of getting your dream job. Though relatively old (2018), this article has given me the motivation and has become my motivation on learning OS, and serves as a nice high overview with topics mentioned: process, memory management, locks, virtual memory, and paging.
